{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Loading item properties...\n",
      "âœ… Item properties merged and saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "DATA_PATH = r\"C:\\Users\\Batia\\Downloads\\RetailRocket rec sys\"\n",
    "\n",
    "print(\" Loading item properties...\")\n",
    "\n",
    "# Load both parts\n",
    "properties_1 = pd.read_csv(os.path.join(DATA_PATH, \"item_properties_part1.csv\"))\n",
    "properties_2 = pd.read_csv(os.path.join(DATA_PATH, \"item_properties_part2.csv\"))\n",
    "\n",
    "# Combine both files\n",
    "properties = pd.concat([properties_1, properties_2])\n",
    "\n",
    "# Drop duplicates, keeping the latest entry per item\n",
    "properties = properties.sort_values(\"timestamp\").drop_duplicates(subset=[\"itemid\"], keep=\"last\")\n",
    "\n",
    "# Save merged properties\n",
    "properties.to_csv(os.path.join(DATA_PATH, \"merged_item_properties.csv\"), index=False)\n",
    "\n",
    "print(\" Item properties merged and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products in properties1: 417053\n",
      "Products in properties2: 417053\n",
      "Products in merged properties: 417053\n"
     ]
    }
   ],
   "source": [
    "print(f\"Products in properties1: {len(properties_1['itemid'].unique())}\")\n",
    "print(f\"Products in properties2: {len(properties_2['itemid'].unique())}\")\n",
    "print(f\"Products in merged properties: {len(properties['itemid'].unique())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "DATA_PATH = r\"C:\\Users\\Batia\\Downloads\\RetailRocket rec sys\"\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(os.path.join(DATA_PATH, \"processed_retailrocket.csv\"))\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp_x\"], unit=\"ms\")\n",
    "\n",
    "# New time-based split\n",
    "train_end = \"2015-07-31\"  # Train: Until July 2015\n",
    "val_end = \"2015-08-31\"    # Validation: August 2015\n",
    "\n",
    "# Split data\n",
    "train_df = df[df[\"timestamp\"] <= train_end]\n",
    "val_df = df[(df[\"timestamp\"] > train_end) & (df[\"timestamp\"] <= val_end)]\n",
    "test_df = df[df[\"timestamp\"] > val_end]  # Test: September 2015\n",
    "\n",
    "# Save new splits\n",
    "train_df.to_csv(os.path.join(DATA_PATH, \"train_retailrocket.csv\"), index=False)\n",
    "val_df.to_csv(os.path.join(DATA_PATH, \"validation_retailrocket.csv\"), index=False)\n",
    "test_df.to_csv(os.path.join(DATA_PATH, \"test_retailrocket.csv\"), index=False)\n",
    "\n",
    "print(\" Dataset successfully split into train, validation, and test sets!\")\n",
    "print(f\" Train: {len(train_df)} rows | Validation: {len(val_df)} rows | Test: {len(test_df)} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "DATA_PATH = r\"C:\\Users\\Batia\\Downloads\\RetailRocket rec sys\"\n",
    "\n",
    "df = pd.read_csv(os.path.join(DATA_PATH, \"processed_retailrocket.csv\"))\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp_x\"], unit=\"ms\")\n",
    "\n",
    "# Check min/max timestamps\n",
    "print(f\" Min Timestamp: {df['timestamp'].min()}\")\n",
    "print(f\" Max Timestamp: {df['timestamp'].max()}\")\n",
    "\n",
    "# Count how many rows should be in each split\n",
    "print(f\" Rows before 2015-12-31 (Train): {len(df[df['timestamp'] <= '2015-12-31'])}\")\n",
    "print(f\" Rows in Jan 2016 (Validation): {len(df[(df['timestamp'] > '2015-12-31') & (df['timestamp'] <= '2016-01-31')])}\")\n",
    "print(f\" Rows after Jan 2016 (Test): {len(df[df['timestamp'] > '2016-01-31'])}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
